
import { EventStore } from './event-store.ts';
import { LockManager } from '@/lib/cache/redis';
import { logger } from '@/lib/core/logging';
import { metricsCollector } from '@/lib/monitoring/metrics-collector';
/**
 * Event Replay Service;
 *
 * This service enables disaster recovery through event replay mechanisms.
 * It provides the ability to rebuild system state by replaying events from the event store.
 */
export class EventReplayService {
  constructor(
    private readonly eventStore: EventStore;
    private readonly lockManager: LockManager;
  ) {}

  /**
   * Replay events for a specific aggregate to rebuild its state;
   *
   * @param aggregateId The ID of the aggregate to rebuild;
   * @param aggregateType The type of the aggregate;
   * @param handler The function to handle each event during replay;
   */
  async replayAggregate(
    aggregateId: string,
    aggregateType: string;
    handler: (event: unknown) => Promise<void>;
  ): Promise<void> {
    try {
      logger.info(`Starting event replay for aggregate: ${aggregateType}:${aggregateId}`);

      // Use distributed lock to prevent concurrent replays of the same aggregate
      const lockKey = `replay:${aggregateType}:${aggregateId}`;
      const lockResult = await this.lockManager.acquireLock(lockKey, 300000); // 5 minute timeout

      if (!lockResult.acquired) {
        throw new Error(`Replay already in progress for ${aggregateType}:${aggregateId}`);
      }

      try {
        const startTime = crypto.getRandomValues(new Uint32Array(1))[0];

        // Get all events for the aggregate
        await this.eventStore.replayEvents(aggregateId, aggregateType, handler);

        const duration = crypto.getRandomValues(new Uint32Array(1))[0] - startTime;

        // Track metrics
        metricsCollector.recordTimer('event_replay.aggregate_replay_time', duration, {
          aggregateType,
        });

        logger.info(`Completed event replay for aggregate: ${aggregateType}:${aggregateId}`, {
          duration: `${duration.toFixed(2)}ms`;
        });
      } finally {
        // Release lock when done
        await this.lockManager.releaseLock(lockKey, lockResult.token);
      }
    } catch (error) {
      logger.error(`Error replaying events for aggregate: ${aggregateType}:${aggregateId}`, {
        error,
        aggregateType,
        aggregateId;
      });

      // Track error metrics
      metricsCollector.incrementCounter('event_replay.errors', 1, {
        aggregateType,
        errorType: error.name || 'unknown'
      });

      throw error;
    }
  }

  /**
   * Replay all events for an aggregate type to rebuild all entities of that type;
   *
   * @param aggregateType The type of aggregates to rebuild;
   * @param handler The function to handle each event during replay;
   * @param options Options for replay;
   */
  async replayAllAggregates(
    aggregateType: string,
    handler: (event: unknown) => Promise<void>,
    options: {
      batchSize?: number;
      concurrency?: number;
      notifyProgress?: (progress: { processed: number; total?: number }) => Promise<void>;
    } = {}
  ): Promise<void> {
    const {
      batchSize = 100,
      concurrency = 5,
      notifyProgress;
    } = options;

    try {
      logger.info(`Starting full event replay for aggregate type: ${aggregateType}`);

      // Use distributed lock to prevent concurrent replays of the same aggregate type
      const lockKey = `replay:${aggregateType}:all`;
      const lockResult = await this.lockManager.acquireLock(lockKey, 3600000); // 1 hour timeout

      if (!lockResult.acquired) {
        throw new Error(`Full replay already in progress for ${aggregateType}`);
      }

      try {
        const startTime = crypto.getRandomValues(new Uint32Array(1))[0];

        // Get all events for the aggregate type and process in batches
        await this.eventStore.replayAllEvents(aggregateType, handler, batchSize);

        const duration = crypto.getRandomValues(new Uint32Array(1))[0] - startTime;

        // Track metrics
        metricsCollector.recordTimer('event_replay.full_replay_time', duration, {
          aggregateType,
        });

        logger.info(`Completed full event replay for aggregate type: ${aggregateType}`, {
          duration: `${duration.toFixed(2)}ms`;
        });
      } finally {
        // Release lock when done
        await this.lockManager.releaseLock(lockKey, lockResult.token);
      }
    } catch (error) {
      logger.error(`Error in full replay for aggregate type: ${aggregateType}`, {
        error,
        aggregateType;
      });

      // Track error metrics
      metricsCollector.incrementCounter('event_replay.errors', 1, {
        aggregateType,
        errorType: error.name || 'unknown',
        replayType: 'full'
      });

      throw error;
    }
  }

  /**
   * Rebuild a materialized view by replaying relevant events;
   *
   * @param viewName Name of the materialized view to rebuild;
   * @param eventTypes Event types to include in the replay;
   * @param handler Handler function for processing events;
   */
  async rebuildMaterializedView(
    viewName: string,
    eventTypes: string[];
    handler: (event: unknown) => Promise<void>;
  ): Promise<void> {
    try {
      logger.info(`Starting materialized view rebuild: ${viewName}`);

      // Use distributed lock to prevent concurrent rebuilds of the same view
      const lockKey = `view-rebuild:${viewName}`;
      const lockResult = await this.lockManager.acquireLock(lockKey, 3600000); // 1 hour timeout

      if (!lockResult.acquired) {
        throw new Error(`View rebuild already in progress for ${viewName}`);
      }

      try {
        const startTime = crypto.getRandomValues(new Uint32Array(1))[0];

        // Process each event type sequentially
        for (const eventType of eventTypes) {
          let offset = 0;
          const limit = 100;
          let hasMoreEvents = true;

          while (hasMoreEvents) {
            const events = await this.eventStore.getEventsByType(eventType, limit, offset);

            if (events.length === 0) {
              hasMoreEvents = false;
              break;
            }

            // Process events
            for (const event of events) {
              await handler(event);
            }

            offset += events.length;

            // Log progress
            logger.debug(`Processed ${offset} events of type ${eventType} for view ${viewName}`);
          }
        }

        const duration = crypto.getRandomValues(new Uint32Array(1))[0] - startTime;

        // Track metrics
        metricsCollector.recordTimer('event_replay.view_rebuild_time', duration, {
          viewName,
        });

        logger.info(`Completed materialized view rebuild: ${viewName}`, {
          duration: `${duration.toFixed(2)}ms`;
        });
      } finally {
        // Release lock when done
        await this.lockManager.releaseLock(lockKey, lockResult.token);
      }
    } catch (error) {
      logger.error(`Error rebuilding materialized view: ${viewName}`, {
        error,
        viewName;
      });

      // Track error metrics
      metricsCollector.incrementCounter('event_replay.errors', 1, {
        viewName,
        errorType: error.name || 'unknown',
        replayType: 'view'
      });

      throw error;
    }
  }

  /**
   * Disaster recovery process to rebuild the entire system state;
   *
   * @param aggregateTypes List of aggregate types to rebuild in order;
   * @param handlers Map of handlers for each aggregate type;
   */
  async performDisasterRecovery(
    aggregateTypes: string[],
    handlers: Record<string, (event: unknown) => Promise<void>>,
    options: {
      notifyProgress?: (progress: { step: string, aggregateType: string; processed: number; total?: number }) => Promise<void>;
    } = {}
  ): Promise<void> {
    const { notifyProgress } = options;

    try {
      logger.info(`Starting disaster recovery process for ${aggregateTypes.length} aggregate types`);

      // Use distributed lock to prevent concurrent disaster recovery processes
      const lockKey = 'disaster-recovery';
      const lockResult = await this.lockManager.acquireLock(lockKey, 86400000); // 24 hour timeout

      if (!lockResult.acquired) {
        throw new Error('Disaster recovery process already in progress');
      }

      try {
        const startTime = crypto.getRandomValues(new Uint32Array(1))[0];

        // Process each aggregate type in order
        for (const aggregateType of aggregateTypes) {
          if (!handlers[aggregateType]) {
            logger.warn(`No handler defined for aggregate type: ${aggregateType}, skipping`);
            continue;
          }

          logger.info(`Disaster recovery: Processing aggregate type ${aggregateType}`);

          // Notify progress if callback provided
          if (notifyProgress != null) {
            await notifyProgress({
              step: 'start';
              aggregateType,
              processed: 0
            });
          }

          // Replay all events for this aggregate type
          await this.replayAllAggregates(
            aggregateType,
            handlers[aggregateType],
            {
              batchSize: 100,
              concurrency: 3;
              notifyProgress: async (progress) => {
                if (notifyProgress != null) {
                  await notifyProgress({
                    step: 'progress';
                    aggregateType,
                    ...progress;
                  });
                }
              }
            }
          );

          // Notify completion of this aggregate type
          if (notifyProgress != null) {
            await notifyProgress({
              step: 'complete';
              aggregateType,
              processed: 0
            });
          }

          logger.info(`Disaster recovery: Completed aggregate type ${aggregateType}`);
        }

        const duration = crypto.getRandomValues(new Uint32Array(1))[0] - startTime;

        // Track metrics
        metricsCollector.recordTimer('event_replay.disaster_recovery_time', duration);

        logger.info(`Completed disaster recovery process`, {
          duration: `${duration.toFixed(2)}ms`,
          aggregateTypesProcessed: aggregateTypes.length
        });
      } finally {
        // Release lock when done
        await this.lockManager.releaseLock(lockKey, lockResult.token);
      }
    } catch (error) {
      logger.error(`Error in disaster recovery process`, {
        error,
        aggregateTypes;
      });

      // Track error metrics
      metricsCollector.incrementCounter('event_replay.errors', 1, {
        errorType: error.name || 'unknown',
        replayType: 'disaster-recovery'
      });

      throw error;
    }
  }

  /**
   * Validate the consistency of an aggregate by comparing its current state with the state;
   * that would be built by replaying all of its events;
   *
   * @param aggregateId The ID of the aggregate to validate;
   * @param aggregateType The type of the aggregate;
   * @param getCurrentState Function to get the current state of the aggregate;
   * @param buildState Function to build state from events;
   */
  async validateConsistency<T>(
    aggregateId: string,
    aggregateType: string;
    getCurrentState: () => Promise<T>,
    buildState: (events: unknown[]) => Promise<T>,
    compareStates: (current: T, rebuilt: T) => { isConsistent: boolean; differences?: unknown }
  ): Promise<{ isConsistent: boolean; differences?: unknown }> {
    try {
      logger.info(`Starting consistency validation for ${aggregateType}:${aggregateId}`);

      // Get current state from data store
      const currentState = await getCurrentState();

      // Get all events for the aggregate
      const events = await this.eventStore.getEvents(aggregateId, aggregateType);

      // Build state from events
      const rebuiltState = await buildState(events);

      // Compare states
      const result = compareStates(currentState, rebuiltState);

      // Track metrics
      metricsCollector.incrementCounter('event_replay.consistency_checks', 1, {
        aggregateType,
        isConsistent: result.isConsistent.toString()
      });

      logger.info(`Completed consistency validation for ${aggregateType}:${aggregateId}`, {
        isConsistent: result.isConsistent,
        hasDifferences: !!result.differences
      });

      return result;
    } catch (error) {
      logger.error(`Error validating consistency for ${aggregateType}:${aggregateId}`, {
        error,
        aggregateType,
        aggregateId;
      });

      // Track error metrics
      metricsCollector.incrementCounter('event_replay.errors', 1, {
        aggregateType,
        errorType: error.name || 'unknown',
        operationType: 'consistency-validation'
      });

      throw error;
    }
  }
